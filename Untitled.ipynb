{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from IPython.core.display import display, HTML\n",
    "from pprint import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib2\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "########  USER INPUTS  ###################\n",
    "longWork = False\n",
    "beautify = True\n",
    "#Enter the link of the channel here\n",
    "urlList = [\"https://www.youtube.com/user/PewDiePie/videos\",\"https://www.youtube.com/user/sabtv/videos\"] \n",
    "\n",
    "\n",
    "#############################################\n",
    "\n",
    "def color_negative_red(val):\n",
    "    \"\"\"\n",
    "    Takes a scalar and returns a string with\n",
    "    the css property `'color: red'` for negative\n",
    "    strings, black otherwise.\n",
    "    \"\"\"\n",
    "    color = 'red' if val > 10 else 'black'\n",
    "    return 'color: %s' % color\n",
    "\n",
    "\n",
    "def getUpload(href):\n",
    "    #This is the Date of uplad of the video\n",
    "\turl=\"https://www.youtube.com\"+href\n",
    "\tsc = requests.get(url)\n",
    "\too = str()\n",
    "\tsoup = BeautifulSoup(sc.text,'html.parser')\n",
    "\too = soup.find_all(\"strong\", class_=\"watch-time-text\")[0].text[13:]\n",
    "\treturn oo\n",
    "\t# return date\n",
    "\n",
    "def buildDict(listValuePair):\n",
    "\tdi = dict()\n",
    "\tfor col,row in attributes:\n",
    "\t\tdi[col] = row \n",
    "\treturn di\n",
    "\n",
    "def channelTotal(url):\n",
    "    global TotalViews,TotalSubscriber,ChannelName\n",
    "    urlAbout = url.replace('videos','about')\n",
    "    sc = requests.get(urlAbout)\n",
    "    soup = BeautifulSoup(sc.text,'html.parser')\n",
    "    about_list = soup.find_all(\"span\",class_=\"about-stat\")\n",
    "    # subdcribers = about_list[0].span.text\n",
    "    TotalViews = about_list[1].text[2:]\n",
    "    TotalSubscriber = about_list[0].text\n",
    "    ChannelName=soup.title.text.replace('YouTube','').replace('-','').replace('\\n','')\n",
    "    print \"----------\", ChannelName.upper() ,\"----------\"\n",
    "    print \"Total Views: \", TotalViews\n",
    "    print \"Total Subscribers: \", TotalSubscriber\n",
    "    print about_list[2].text\n",
    "    \n",
    "attributes = [('Title',titlePd),('Duration',durPd),('Views',viewPd),('Upladed Ago',uploadLagPd)]\n",
    "\n",
    "\n",
    "\n",
    "for url in urlList:\n",
    "\tchannelTotal(url)\n",
    "\n",
    "\tsc = requests.get(url)\n",
    "\n",
    "\tsoup = BeautifulSoup(sc.text,'html.parser')\n",
    "\t# anime = soup.select('li a')\n",
    "\n",
    "\n",
    "\tvideo_Alllists = soup.find_all(\"div\", class_=\"yt-lockup-content\")\n",
    "\ttitle = list()\n",
    "\tduration = list()\n",
    "\tuploadLag = list()\n",
    "\tdate = list()\n",
    "\tview = list()\n",
    "\tviewPercent = list()\n",
    "\td = dict()\n",
    "\n",
    "\tfor line in video_Alllists:\n",
    "\t\tif longWork:\n",
    "\t\t\tdate.append(getUpload(line.a.get('href')))\n",
    "\t\tuploadLag.append(line.find_all('li')[1].text)\n",
    "\t\tview.append(line.li.text)\n",
    "\t\ttitle.append(line.a.get('title'))\n",
    "\t\tduration.append(re.findall('\\d.*',line.span.text)[0][:-1])\n",
    "\n",
    "\t    \n",
    "\ttitlePd = pd.Series(title)\n",
    "\tdurPd = pd.Series(duration)\n",
    "\tviewPd = pd.Series(view)\n",
    "\tuploadLagPd = pd.Series(uploadLag)\n",
    "\n",
    "\n",
    "\n",
    "\t\n",
    "\n",
    "\tif longWork:\n",
    "\t\td['Date'] = pd.Series(date)\n",
    "\t    \n",
    "\td = buildDict(attributes)\n",
    "\tdf = pd.DataFrame(d)\n",
    "\tdf.title = ChannelName\n",
    "\tdf.to_pickle('DataFrames/'+ df.title)\n",
    "\tdf_old = pd.read_pickle('DataFrames/'+ df.title)\n",
    "\tdf = pd.concat([df_old,df]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "\t#Finding the %age of the views\n",
    "\tview_sum = int(TotalViews.replace('views',' ').replace(',',''))\n",
    "\tfor eachView in df['Views']:\n",
    "\t    viewPercent.append(round(int(eachView.replace('views',' ').replace(',',''))/view_sum*100,2))\n",
    "\tviewPercentPd = pd.Series([str(a) +'%' for a in viewPercent])\n",
    "\tdf['View Percentage'] = viewPercentPd\n",
    "\tif beautify:\n",
    "\t\tdisplay(HTML(df.to_html()))\n",
    "\telse:\n",
    "\t\tdf.style.bar(subset=['Views'], color='#d65f5f') ##Fails because its in string\n",
    "print \"======Done=====\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pprint(df.to_html())\n",
    "# print df.to_html()\n",
    "display(HTML(df.to_html()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', '14'],\n",
    "                    'B': ['B0', 'B1', 'B2', '43'],\n",
    "                    'C': ['C0', 'C1', 'C2', '44'],\n",
    "                    'D': ['D0', 'D1', 'D2', '46']},\n",
    "                     )\n",
    "df2 = pd.DataFrame({'A': ['14', '45', '16', '47'],\n",
    "                    'B': ['43', '55', '96', '67'],\n",
    "                    'C': ['44', '75', '56', '77'],\n",
    "                    'D': ['46', '25', '36', '97']},\n",
    "                     )\n",
    "pprint(df1)\n",
    "pprint(df2)\n",
    "result = pd.concat([df1,df2]).drop_duplicates().reset_index(drop=True)\n",
    "# df1.append(df2\n",
    "# pprint(df2)\n",
    "\n",
    "# result = pd.merge(df1,df2, how='left',on=['A','B','C','D'],sort=False)\n",
    "pprint(result)\n",
    "df2.name = 'ss'\n",
    "df2.name\n",
    "print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd758cd9050>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# pprint(df.title)\n",
    "savedDF = pd.read_pickle('DataFrames/'+ '  n  ')\n",
    "dic = {\n",
    "    'Duration':['2 minutes, 49 seconds','2 minutes, 46 seconds'],\n",
    "    'Title':['Ankur ji ka kamal','Sachi Ka kamaal'],\n",
    "    'Upladed Ago':['2 hours Ago','1 hours Ago'],\n",
    "    'Views':['52,612 views','128,714 views'],\n",
    "}\n",
    "badDF = pd.DataFrame(dic)\n",
    "savedDF= pd.concat([badDF,savedDF],ignore_index=True)\n",
    "pprint(savedDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:env]",
   "language": "python",
   "name": "conda-env-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
