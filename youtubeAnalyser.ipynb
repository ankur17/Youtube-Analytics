{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from IPython.core.display import display, HTML\n",
    "from pprint import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib2\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "# from tqdm import tqdm\n",
    "import thread as th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "########  USER INPUTS  ###################\n",
    "longWork = True\n",
    "beautify = True\n",
    "#Enter the link of the channel here\n",
    "urlList = list()\n",
    "handle = open('./ChannelList.txt','r')\n",
    "for a in handle:\n",
    "    ss = re.findall('https://www.youtube.com/.*videos',a)\n",
    "    if len(ss):\n",
    "        urlList.append(ss[0])\n",
    "handle.close()\n",
    "\n",
    "\n",
    "#############################################\n",
    "\n",
    "def color_negative_red(val):\n",
    "    \"\"\"\n",
    "    Takes a scalar and returns a string with\n",
    "    the css property `'color: red'` for negative\n",
    "    strings, black otherwise.\n",
    "    \"\"\"\n",
    "    color = 'red' if val > 10 else 'black'\n",
    "    return 'color: %s' % color\n",
    "\n",
    "\n",
    "def getUpload(href):\n",
    "    #This is the Date of uplad of the video\n",
    "\turl=\"https://www.youtube.com\"+href\n",
    "\tsc = requests.get(url)\n",
    "\too = str()\n",
    "\tsoup = BeautifulSoup(sc.text,'html.parser')\n",
    "\too = soup.find_all(\"strong\", class_=\"watch-time-text\")[0].text[13:]\n",
    "\treturn oo\n",
    "\t# return date\n",
    "\n",
    "def buildDict(listValuePair):\n",
    "\tdi = dict()\n",
    "\tfor col,row in attributes:\n",
    "\t\tdi[col] = row \n",
    "\treturn di\n",
    "\n",
    "def channelTotal(url):\n",
    "    global TotalViews,TotalSubscriber,ChannelName\n",
    "    urlAbout = url.replace('videos','about')\n",
    "    sc = requests.get(urlAbout)\n",
    "    soup = BeautifulSoup(sc.text,'html.parser')\n",
    "    about_list = soup.find_all(\"span\",class_=\"about-stat\")\n",
    "    # subdcribers = about_list[0].span.text\n",
    "    TotalViews = about_list[1].text[2:]\n",
    "    TotalSubscriber = about_list[0].text\n",
    "    ChannelName=soup.title.text.replace('YouTube','').replace('-','').replace('\\n','')\n",
    "    print \"----------\", ChannelName.upper() ,\"----------\"\n",
    "    print \"Total Views: \", TotalViews\n",
    "    print \"Total Subscribers: \", TotalSubscriber\n",
    "    print about_list[2].text\n",
    "    \n",
    "\n",
    "for url in urlList:\n",
    "\tchannelTotal(url)\n",
    "# \tth.start_new_thread( channelTotal, (url,) )\n",
    "    \n",
    "\tsc = requests.get(url)\n",
    "\n",
    "\tsoup = BeautifulSoup(sc.text,'html.parser')\n",
    "\n",
    "\tvideo_Alllists = soup.find_all(\"div\", class_=\"yt-lockup-content\")\n",
    "\ttitle = list()\n",
    "\tduration = list()\n",
    "\tuploadLag = list()\n",
    "\tdate = list()\n",
    "\tview = list()\n",
    "\tviewPercent = list()\n",
    "\td = dict()\n",
    "\n",
    "\tfor line in video_Alllists:\n",
    "\t\tif longWork:\n",
    "\t\t\tdate.append(getUpload(line.a.get('href')))\n",
    "\t\tuploadLag.append(line.find_all('li')[1].text)\n",
    "\t\tview.append(line.li.text)\n",
    "\t\ttitle.append(line.a.get('title'))\n",
    "\t\tduration.append(re.findall('\\d.*',line.span.text)[0][:-1])\n",
    "\n",
    "\tdatePD = pd.Series(date)    \n",
    "\ttitlePd = pd.Series(title)\n",
    "\tdurPd = pd.Series(duration)\n",
    "\tviewPd = pd.Series(view)\n",
    "\tuploadLagPd = pd.Series(uploadLag)\n",
    "\tattributes = [('Title',titlePd),('Duration',durPd),('Views',viewPd),('Upladed Ago',uploadLagPd)]\n",
    "\n",
    "\td = buildDict(attributes)\n",
    "\tdf = pd.DataFrame(d)\n",
    "    \n",
    "    \n",
    "\tif longWork:\n",
    "\t\tdf['Date'] = pd.Series(date)\n",
    "\t   \n",
    "\t\n",
    "\tif not os.path.isfile('./DataFrames/'+ChannelName):\n",
    "\t\tdf.to_pickle('DataFrames/'+ ChannelName)\n",
    "        \n",
    "\t\n",
    "\tdf_old = pd.read_pickle('DataFrames/'+ ChannelName)\n",
    "\tdf = pd.concat([df,df_old]).drop_duplicates(subset=['Duration','Title']).reset_index(drop=True)\n",
    "#     ,ignore_index=True\n",
    "# \ttry:\n",
    "# \t\tfake = df_old.analyticStartDate\n",
    "# \texcept:\n",
    "# \t\tdf.analyticStartDate = time.ctime()\n",
    "# \tprint \"Analytics Starting time:\",df.analyticStartDate\n",
    "    \n",
    "# \t#Updating the saves\n",
    "\tdf.to_pickle('DataFrames/'+ ChannelName)  ####FOR DEBUGGING#####\n",
    "    \n",
    "\t#Finding the %age of the views\n",
    "\tview_sum = int(TotalViews.replace('views',' ').replace(',',''))\n",
    "\tfor eachView in df['Views']:\n",
    "\t    viewPercent.append(round(int(eachView.replace('views',' ').replace(',',''))/view_sum*100,2))\n",
    "\tviewPercentPd = pd.Series([str(a) +'%' for a in viewPercent])\n",
    "\tdf['View Percentage'] = viewPercentPd\n",
    "\tif beautify:\n",
    "\t\tdisplay(HTML(df.to_html()))\n",
    "\telse:\n",
    "\t\ts = df.style.applymap(color_negative_red)\n",
    "\t\tdf.style.bar(subset=['Views'], color='#d65f5f') ##Fails because its in string\n",
    "print \"======Done=====\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#####TESTING WORK############\n",
    "import sys\n",
    "# pprint(df.title)\n",
    "savedDF = pd.read_pickle('DataFrames/'+ '  SAB TV  ')\n",
    "dic = {\n",
    "    'Duration':['2 minutes, 49 seconds','2 minutes, 46 seconds'],\n",
    "    'Title':['Ankur ji ka kamal','Sachi Ka kamaal'],\n",
    "    'Upladed Ago':['2 hours Ago','1 hours Ago'],\n",
    "    'Views':['52,612 views','128,714 views'],\n",
    "}\n",
    "badDF = pd.DataFrame(dic)\n",
    "display(HTML(savedDF.to_html()))\n",
    "savedDF= pd.concat([badDF,savedDF],ignore_index=True)\n",
    "pprint(savedDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#####TESTING WORK############\n",
    "# os.listdir('./DataFrames/')\n",
    "os.path.isfile('./DataFrames/'+ '  2point5  ' )\n",
    "read = pd.read_pickle('DataFrames/'+ '  2point5  ' )\n",
    "display(HTML(read.to_html()))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:env]",
   "language": "python",
   "name": "conda-env-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
